{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from rdkit import Chem\n",
    "\n",
    "# FEATURES\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem # For Morgan Fingerprint (Circular Fingerprints)\n",
    "from rdkit.Chem import MACCSkeys # For MACCS keys\n",
    "\n",
    "# SCALING DATA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# For splitting data into training and test sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For processing how well our methods have classified our data\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score,roc_auc_score\n",
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Logistic Regression ML Model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "###\n",
    "###    User Defined Helper Functions\n",
    "###\n",
    "####################################################################\n",
    "\n",
    "# FUNCTION LOAD_DATA\n",
    "# Load the data from the csv file in the [data] folder. We separate \n",
    "# the molecule data from the \"explosive\" labes and return the labels\n",
    "# an a molecules from SMILES representation for each molecule in the \n",
    "# dataset\n",
    "def load_data(data_file):\n",
    "    mol_df = pd.read_csv(data_file)\n",
    "\n",
    "    smiles = np.array(mol_df['smiles'])\n",
    "    labels = np.array(mol_df['labels']) \n",
    "    \n",
    "    mols = np.array([Chem.MolFromSmiles(smile) for smile in smiles])\n",
    "    \n",
    "    return mols, labels\n",
    "\n",
    "# FUNCTION GEN_FPRINTS\n",
    "# Generate molecule fingerprints for each molecule in an input list\n",
    "def gen_fprints(mols):\n",
    "    f_prints = np.array([Chem.RDKFingerprint(mol) for mol in mols])  \n",
    "    return f_prints\n",
    "\n",
    "# FUNCTION gen_MACCS \n",
    "# Generate the MACCS keys for each molecule in an input list of molecules\n",
    "def gen_MACCS(mols):\n",
    "    MACCS_keys = np.array([MACCSkeys.GenMACCSKeys(mol) for mol in mols])\n",
    "    return MACCS_keys\n",
    "\n",
    "# FUNCTION gen_morgan_prints\n",
    "# Generates Morgan finger prints for each molecule in an input list of molecules\n",
    "def gen_morgan_prints(mols,radius):\n",
    "    morgan_prints = np.array([AllChem.GetMorganFingerprintAsBitVect(mol,radius,nBits=1024) for mol in mols])\n",
    "    return morgan_prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'molecule_data.csv'\n",
    "mols, labels = load_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load different molecular features separately\n",
    "##############################################\n",
    "#rdk_features    = gen_fprints(mols)\n",
    "#maccs_features  = gen_MACCS(mols)\n",
    "morgan_features = gen_morgan_prints(mols,radius=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for [training] and [testing]\n",
    "morgan_train, morgan_test, label_train, label_test = train_test_split(morgan_features, labels, \\\n",
    "                                                                test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Principal Components\n",
    "######################\n",
    "\n",
    "# Determine principal components using [training data] and apply the transformation to the [test data]\n",
    "PC_morgan_proj = PCA(n_components=4)\n",
    "morgan_proj_train = PC_morgan_proj.fit_transform(morgan_train)\n",
    "morgan_proj_test = PC_morgan_proj.transform(morgan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#\n",
    "# Model with PCA\n",
    "#\n",
    "#########################################################################\n",
    "# Train Logistic Regression model using PC transformed Morgan features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Generalizability Analysis\n",
    "accuracy = accuracy_score(label_test, pred)\n",
    "conf_matrix = confusion_matrix(label_test, pred)\n",
    "F1Score = f1_score(label_test,pred)\n",
    "roc_auc = roc_auc_score(label_test,pred)\n",
    "recall = recall_score(label_test,pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(conf_matrix)\n",
    "\n",
    "print('\\nRecall')\n",
    "print(recall)  \n",
    "\n",
    "print('\\nAccuracy')\n",
    "print(accuracy)  \n",
    "\n",
    "print('\\nF1 Score')\n",
    "print(F1Score)\n",
    "\n",
    "print('\\nROC AUC Score')\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#\n",
    "# Model [WITHOUT] PCA\n",
    "#\n",
    "#########################################################################\n",
    "# Train Logistic Regression model using PC transformed Morgan features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Generalizability Analysis\n",
    "accuracy = accuracy_score(label_test, pred)\n",
    "conf_matrix = confusion_matrix(label_test, pred)\n",
    "F1Score = f1_score(label_test,pred)\n",
    "roc_auc = roc_auc_score(label_test,pred)\n",
    "recall = recall_score(label_test,pred)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(conf_matrix)\n",
    "\n",
    "print('\\nRecall')\n",
    "print(recall)  \n",
    "\n",
    "print('\\nAccuracy')\n",
    "print(accuracy)  \n",
    "\n",
    "print('\\nF1 Score')\n",
    "print(F1Score)\n",
    "\n",
    "print('\\nROC AUC Score')\n",
    "print(roc_auc)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
